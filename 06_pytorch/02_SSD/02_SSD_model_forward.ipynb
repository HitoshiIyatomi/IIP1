{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_SSD_model_forward.ipynb\n",
    "\n",
    "### Create SSD network model and its forward function.\n",
    "\n",
    "### SSD model is composed four modules: \n",
    "###       (1) VGG, (2) extra, (3) loc, and (4) conf modules.\n",
    "\n",
    "\n",
    "This includes Non-Maximum Supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SezJNFsGw8U"
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "from math import sqrt\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Implement VGG-module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "seziJ76uGw8b",
    "outputId": "a23d228c-e2fb-469b-c3b5-88ea6e5fb5df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "  (32): ReLU(inplace=True)\n",
      "  (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (34): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create 34 layered VGG module\n",
    "def make_vgg():\n",
    "    layers = []\n",
    "    in_channels = 3  # num of color channel\n",
    "\n",
    "    # configuration of network\n",
    "    # definition of number of feature maps in each layer \n",
    "    #     OR definition of max pooling as 'M' in VGG modules \n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256,\n",
    "           256, 'MC', 512, 512, 512, 'M', 512, 512, 512]\n",
    "\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        elif v == 'MC':\n",
    "            # 'ceil_mode' rounds up float results into integer\n",
    "            #  (in default: output is rounding down in 'floor' mode)\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "\n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)\n",
    "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "    layers += [pool5, conv6,\n",
    "               nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "\n",
    "# confirmation\n",
    "vgg_test = make_vgg()\n",
    "print(vgg_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement extra module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i04NYMoGw8h",
    "outputId": "af5cf9cd-4011-4d63-fab5-7ba4eed77075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create 8 layered extra module\n",
    "def make_extras():\n",
    "    layers = []\n",
    "    in_channels = 1024  # input channel from VGG module\n",
    "\n",
    "    # configuration of extra network (number of feature maps)\n",
    "    cfg = [256, 512, 128, 256, 128, 256, 128, 256]\n",
    "\n",
    "    layers += [nn.Conv2d(in_channels, cfg[0], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[0], cfg[1], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[1], cfg[2], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[2], cfg[3], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[3], cfg[4], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[4], cfg[5], kernel_size=(3))]\n",
    "    layers += [nn.Conv2d(cfg[5], cfg[6], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[6], cfg[7], kernel_size=(3))]\n",
    "    \n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "\n",
    "# confirmation\n",
    "extras_test = make_extras()\n",
    "print(extras_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of (3) loc, and (4) conf modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vXKr2WnGw8o",
    "outputId": "f085d3ef-d4ea-48ff-cca0-c67aeafa8b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create loc_layers: output the offset of the default box\n",
    "# create conf_layers: output the confidence for each class of the default box\n",
    "\n",
    "\n",
    "def make_loc_conf(num_classes=21, bbox_aspect_num=[4, 6, 6, 6, 4, 4]):\n",
    "\n",
    "    loc_layers = []\n",
    "    conf_layers = []\n",
    "\n",
    "    # conv layer for conv4_3 (22nd layer of VGG [source1])\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[0]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[0]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # conv layer for conv6_2 (the last layer of VGG [source2])\n",
    "    loc_layers += [nn.Conv2d(1024, bbox_aspect_num[1]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(1024, bbox_aspect_num[1]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # conv layer for conv7_2 conv ([source3] in the extra)\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[2]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[2]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # conv layer for conv8_2 conv ([source4] in the extra)\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[3]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[3]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # conv layer for conv9_2 conv ([source5] in the extra)\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[4]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[4]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    # conv layer for conv10_2 conv ([source6] in the extra)\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[5]\n",
    "                             * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[5]\n",
    "                              * num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    return nn.ModuleList(loc_layers), nn.ModuleList(conf_layers)\n",
    "\n",
    "\n",
    "# confirmation\n",
    "loc_test, conf_test = make_loc_conf()\n",
    "print(loc_test)\n",
    "print(conf_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of L2-Norm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8EwzMY9fGw8u"
   },
   "outputs": [],
   "source": [
    "# L2Norm layer after the conv4_3 \n",
    "# This layer received 512x38x38 input\n",
    "# This normalizes the different statistical properties of the feature map for each channel.\n",
    "# See detail in the class slide\n",
    "\n",
    "class L2Norm(nn.Module):\n",
    "    def __init__(self, input_channels=512, scale=20):\n",
    "        super(L2Norm, self).__init__() \n",
    "        self.weight = nn.Parameter(torch.Tensor(input_channels))\n",
    "        self.scale = scale  # initial weights for each layer (alpha) \n",
    "        self.reset_parameters()  # reset parameters\n",
    "        self.eps = 1e-10\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        '''set initial weights for layer (alpha in the slide)'''\n",
    "        init.constant_(self.weight, self.scale)  # all initial weights are set to 20.\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''For each 38×38 feature (x), the route of the sum of squares was obtained over 512 channels (=norm)\n",
    "        each value was divided by the 'norm'. \n",
    "        Then, normalized x is weighted by trainable layer weights (alpha).'''\n",
    "\n",
    "        # normalized the input (x) in channel direction.\n",
    "        # size of 'norm' Tensor is torch.Size([batch_num, 1, 38, 38])\n",
    "        # size of normalized x Tensor is torch.Size([batch_num, 512, 38, 38])\n",
    "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt()+self.eps\n",
    "        x = torch.div(x, norm)\n",
    "\n",
    "        # normalized x is multiplied by layer weights.\n",
    "        # size of self.weight is torch.Size([512]), so it unsqueeze to \n",
    "        # torch.Size([batch_num, 512, 38, 38]) and are multiplied.\n",
    "        weights = self.weight.unsqueeze(\n",
    "            0).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        out = weights * x\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of Default Box (Dbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6K7TmuLGw8z"
   },
   "outputs": [],
   "source": [
    "# Class for outputting the default box\n",
    "class DBox(object):\n",
    "    def __init__(self, cfg):\n",
    "        super(DBox, self).__init__()\n",
    "\n",
    "        # initial setting\n",
    "        self.image_size = cfg['input_size']  # image size = 300\n",
    "        # [38, 19, …] map size of each sorce\n",
    "        self.feature_maps = cfg['feature_maps']\n",
    "        self.num_priors = len(cfg[\"feature_maps\"])  # number of source=6\n",
    "        self.steps = cfg['steps']  # [8, 16, …] pixel size of DBox\n",
    "        \n",
    "        self.min_sizes = cfg['min_sizes']\n",
    "        # [30, 60, …]  size (area) of small square DBox\n",
    "        \n",
    "        self.max_sizes = cfg['max_sizes']\n",
    "        # [60, 111, …] size (area) of big square DBox\n",
    "        \n",
    "        self.aspect_ratios = cfg['aspect_ratios']  # aspect ratio of rectangle DBox\n",
    "\n",
    "    def make_dbox_list(self):\n",
    "        '''creation of DBox'''\n",
    "        mean = []\n",
    "        # 'feature_maps': [38, 19, 10, 5, 3, 1]\n",
    "        for k, f in enumerate(self.feature_maps):\n",
    "            for i, j in product(range(f), repeat=2):  # Make a combination of two pairs of numbers up to f　f_P_2\n",
    "                # i, j are combination of (0,0), (0,1),...(0,37),(1,0),...(1,37),...,(37,37) when f=38\n",
    "                # 'steps': image size (side length) supported by one node on the feature map\n",
    "                # 'steps': [8, 16, 32, 64, 100, 300] (= 300/38, 300/19, 300/10, ...)\n",
    "                f_k = self.image_size / self.steps[k]\n",
    "\n",
    "                # Center coordinates of DBox (cx,cy). Each normalized in [0,1]\n",
    "                cx = (j + 0.5) / f_k\n",
    "                cy = (i + 0.5) / f_k\n",
    "\n",
    "                # small DBow with aspect ratio=1 DBox [cx,cy, width, height]\n",
    "                # 'min_sizes': [30, 60, 111, 162, 213, 264]\n",
    "                s_k = self.min_sizes[k]/self.image_size\n",
    "                mean += [cx, cy, s_k, s_k]\n",
    "\n",
    "                # large DBow with aspect ratio=1 DBox [cx,cy, width, height]\n",
    "                # 'max_sizes': [60, 111, 162, 213, 264, 315],\n",
    "                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))\n",
    "                mean += [cx, cy, s_k_prime, s_k_prime]\n",
    "\n",
    "                # DBox with other aspect ratios [cx,cy, width, height]\n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]\n",
    "                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]\n",
    "\n",
    "        # convert DBox into Tensor torch.Size([8732, 4])\n",
    "        output = torch.Tensor(mean).view(-1, 4)\n",
    "\n",
    "        # To prevent DBox from sticking out of the image, set the size to min=0 and max=1\n",
    "        output.clamp_(max=1, min=0)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMQnyO-VGw83",
    "outputId": "48ff0468-4eac-4d33-ae90-92ffb86fa8a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.961249</td>\n",
       "      <td>0.961249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622254</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     0.013333  0.013333  0.100000  0.100000\n",
       "1     0.013333  0.013333  0.141421  0.141421\n",
       "2     0.013333  0.013333  0.141421  0.070711\n",
       "3     0.013333  0.013333  0.070711  0.141421\n",
       "4     0.040000  0.013333  0.100000  0.100000\n",
       "...        ...       ...       ...       ...\n",
       "8727  0.833333  0.833333  0.502046  1.000000\n",
       "8728  0.500000  0.500000  0.880000  0.880000\n",
       "8729  0.500000  0.500000  0.961249  0.961249\n",
       "8730  0.500000  0.500000  1.000000  0.622254\n",
       "8731  0.500000  0.500000  0.622254  1.000000\n",
       "\n",
       "[8732 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirmation\n",
    "\n",
    "# setting of SSD300 network\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21,  # number of total class (20 objects + background)\n",
    "    'input_size': 300,  # image size\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # aspect ratio of the output DBox\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],  # image size of each 'source'\n",
    "    'steps': [8, 16, 32, 64, 100, 300],  # image size (side length) supported by one node on the feature map\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  # size of small square DBOX\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],  # size of large square DBOX\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "# creation of DBox\n",
    "dbox = DBox(ssd_cfg)\n",
    "dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "# confirmation of the output of DBox \n",
    "pd.DataFrame(dbox_list.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of SSD class (only the architecture) \n",
    "###   full implementation is in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soAjguIYGw89",
    "outputId": "10c682f5-84d2-4646-eb90-88fc739a6495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD(\n",
      "  (vgg): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (34): ReLU(inplace=True)\n",
      "  )\n",
      "  (extras): ModuleList(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (L2Norm): L2Norm()\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Definition of SSD class\n",
    "class SSD(nn.Module):\n",
    "\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "\n",
    "        self.phase = phase  # select train or inference\n",
    "        self.num_classes = cfg[\"num_classes\"]  # number of classes=21\n",
    "\n",
    "        # build the SSD model\n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(\n",
    "            cfg[\"num_classes\"], cfg[\"bbox_aspect_num\"])\n",
    "\n",
    "        # creation of DBox\n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "        # use \"Detect\" when inference mode\n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect()\n",
    "\n",
    "\n",
    "# confirmation\n",
    "ssd_test = SSD(phase=\"train\", cfg=ssd_cfg)\n",
    "print(ssd_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hL7JLRyGw9F"
   },
   "outputs": [],
   "source": [
    "# Function to convert DBox to BBox using offset information\n",
    "\n",
    "def decode(loc, dbox_list):\n",
    "    \"\"\"\n",
    "    Function to convert DBox to BBox using offset information\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loc:  [8732,4]\n",
    "        offset estimated by SSD model\n",
    "        [Δcx, Δcy, Δwidth, Δheight]\n",
    "    dbox_list: [8732,4]\n",
    "        DBox info\n",
    "        [cx, cy, width, height]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boxes : [xmin, ymin, xmax, ymax]\n",
    "        BBox info\n",
    "    \"\"\"\n",
    "\n",
    "    # DBox info is stored in [cx, cy, width, height]\n",
    "    # loc info is stored in [Δcx, Δcy, Δwidth, Δheight]\n",
    "\n",
    "    # get BBox info from offset\n",
    "    boxes = torch.cat((\n",
    "        dbox_list[:, :2] + loc[:, :2] * 0.1 * dbox_list[:, 2:],\n",
    "        dbox_list[:, 2:] * torch.exp(loc[:, 2:] * 0.2)), dim=1)\n",
    "    # size of boxes is torch.Size([8732, 4])\n",
    "\n",
    "    # convert BBox location from [cx, cy, width, height] to [xmin, ymin, xmax, ymax]\n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2  # calc (xmin,ymin)\n",
    "    boxes[:, 2:] += boxes[:, :2]      # calc (xmax,ymax)\n",
    "\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of Non-Maximum Suppression (NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtndAFgxGw9M"
   },
   "outputs": [],
   "source": [
    "# Non-Maximum Suppression (NMS) \n",
    "\n",
    "\n",
    "def nm_suppression(boxes, scores, overlap=0.45, top_k=200):\n",
    "    \"\"\"\n",
    "    Non-Maximum Suppression\n",
    "    remove highly overlapped BBox（use threshold: 'overlap')\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    boxes : [# BBox with larger confidence threshold（0.01),4]\n",
    "        BBox info [xmin, ymin, xmax, ymax]\n",
    "    scores :[# BBox with confidence score larger than threshold（0.01)]\n",
    "        conf info\n",
    "\n",
    "    overlap : detection threshold for overlapping \n",
    "        (IOU > 'threshold' are removed)\n",
    "    top_k   : maxium number of BBoxes to be detected\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    keep : list\n",
    "        Store the index that passed the NMS in the conf in descending order\n",
    "    count：int\n",
    "        Number of BBox passed NMS\n",
    "    \"\"\"\n",
    "\n",
    "    # create a template of return\n",
    "    count = 0\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    # keep：torch.Size([ The number of BBoxes above the confidence threshold])\n",
    "    # all emelents are initialized as 0\n",
    "\n",
    "    # calclate the area (size) of each BBox\n",
    "    x1 = boxes[:, 0] #xmin\n",
    "    y1 = boxes[:, 1] #ymin\n",
    "    x2 = boxes[:, 2] #xmax\n",
    "    y2 = boxes[:, 3] #ymax\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "\n",
    "    # copy BBoxes. tmp area for calculation of IOU\n",
    "    #   IOU (interaction over the union): degree of the overlap of BBoxes\n",
    "    tmp_x1 = boxes.new()\n",
    "    tmp_y1 = boxes.new()\n",
    "    tmp_x2 = boxes.new()\n",
    "    tmp_y2 = boxes.new()\n",
    "    tmp_w = boxes.new()\n",
    "    tmp_h = boxes.new()\n",
    "\n",
    "    # Reorder 'score' in ascending order\n",
    "    v, idx = scores.sort(0)\n",
    "\n",
    "    # pickup index of top_k (upto 200) BBox\n",
    "    idx = idx[-top_k:]\n",
    "\n",
    "    # Unless the number of elements in idx is zero, repeat following process\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # set i as the index whos has the largest confidence score at now\n",
    "\n",
    "        # Add BBox index i (with current largest confidence score) to 'keep' \n",
    "        #  say \"ref-box\"\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "\n",
    "        # Exit the loop at the last BBox\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "\n",
    "        # we have kept the current index i (with largest conf score) in 'keep',\n",
    "        #           so reduce this (id of the \"ref-box\") from idx\n",
    "        idx = idx[:-1] # the idx associate with largest conf score is excluded \n",
    "\n",
    "        # -------------------\n",
    "        # Extracts and removes BBoxes that have a large overlap \n",
    "        #    with the BBoxes stored in 'keep' (ref-box: BBOx with largest conf score)\n",
    "        #   (compare \"ref-box\" with other BBoxes)\n",
    "        # -------------------\n",
    "        # \n",
    "        # A tensor to store the position of the BBox to be compared (tmp_**)\n",
    "        #  number of tmp_** element is upto num of idx-1.\n",
    "        #  ex) x1 is array of xmin of BBox having more than 0.01 conf score\n",
    "        #      tmp_x1 has array of xmin of BBox to be compared (with \"ref-box\") \n",
    "        torch.index_select(x1, 0, idx, out=tmp_x1)\n",
    "        torch.index_select(y1, 0, idx, out=tmp_y1)\n",
    "        torch.index_select(x2, 0, idx, out=tmp_x2)\n",
    "        torch.index_select(y2, 0, idx, out=tmp_y2)\n",
    "\n",
    "        # In order to calculate IOU, \n",
    "        #   clamp the location of BBOxes to be compared to that of the \"ref-box\" \n",
    "        # i.e. they are the coordinates of the four corners of the overlapped area\n",
    "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i])\n",
    "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i])\n",
    "        tmp_x2 = torch.clamp(tmp_x2, max=x2[i])\n",
    "        tmp_y2 = torch.clamp(tmp_y2, max=y2[i])\n",
    "\n",
    "        # resize tensor size for width and height for following calculation\n",
    "        tmp_w.resize_as_(tmp_x2)\n",
    "        tmp_h.resize_as_(tmp_y2)\n",
    "\n",
    "        # Find the width and height of BBox in the clamped state\n",
    "        # (overlapped width and height with the \"ref-box\")\n",
    "        tmp_w = tmp_x2 - tmp_x1\n",
    "        tmp_h = tmp_y2 - tmp_y1\n",
    "\n",
    "        # If the width or height is negative, set it to zero.\n",
    "        tmp_w = torch.clamp(tmp_w, min=0.0)\n",
    "        tmp_h = torch.clamp(tmp_h, min=0.0)\n",
    "\n",
    "        # calculate their area\n",
    "        inter = tmp_w*tmp_h # intersect(a,b)\n",
    "\n",
    "        # IoU = intersect(a,b) / (area(a) + area(b) - intersect(a,b))\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # area of BBox to be compared: area(b)\n",
    "        union = (rem_areas - inter) + area[i]  # area(a)-intersect(a,b)+area(b)\n",
    "        IoU = inter/union \n",
    "\n",
    "        # leave idx whose overlap is smaller than the threshold 'overlap' \n",
    "        idx = idx[IoU.le(overlap)]  # le: Less than or Equal to\n",
    "        # An idx with an IoU greater than the overlap is the same as the idx you initially chose to store in 'keep' \n",
    "        # \n",
    "\n",
    "    # finish this program when while-loop ends\n",
    "\n",
    "    return keep, count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of Detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFV7wK4GGw9T"
   },
   "outputs": [],
   "source": [
    "# From 'conf' and 'loc' from SSD, output BBOx after removing overlapping\n",
    "\n",
    "\n",
    "class Detect(Function):\n",
    "\n",
    "    def __init__(self, conf_thresh=0.01, top_k=200, nms_thresh=0.45):\n",
    "        self.softmax = nn.Softmax(dim=-1)  # softmax fuction for 'conf'\n",
    "        self.conf_thresh = conf_thresh  # threshold for 'conf' (0.01): use DBOx > 0.01 \n",
    "        self.top_k = top_k  # number the maximum DBOX used BBox in the non-maximum suppression (NMS) \n",
    "        self.nms_thresh = nms_thresh  # In NMS, BBoxs with their IOU > nms_th (0.45) is treated as overlapped\n",
    "\n",
    "    def forward(self, loc_data, conf_data, dbox_list):\n",
    "        \"\"\"\n",
    "        forward processing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        loc_data:  [batch_num,8732,4]\n",
    "            offset info\n",
    "        conf_data: [batch_num, 8732, num_classes]\n",
    "           confidence score of DBox\n",
    "        dbox_list: [8732,4]\n",
    "            DBox location info [cx, cy, width, height]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        output : torch.Size([batch_num, 21, 200, 5])\n",
    "            （batch_num, conf score for class, top_k, BBox info）\n",
    "              5 BBOx info: [xmin, ymin, xmax, ymax, label_ind]\n",
    "        \"\"\"\n",
    "\n",
    "        # get size\n",
    "        num_batch = loc_data.size(0)  # mini batch size\n",
    "        num_dbox = loc_data.size(1)  # num DBox = 8732\n",
    "        num_classes = conf_data.size(2)  # num class = 21\n",
    "\n",
    "        # confidence scores from SSD (21 class) are normalized with softmax\n",
    "        conf_data = self.softmax(conf_data)\n",
    "\n",
    "        # prepare output tensor [num minibatch, 21, 200, 5]\n",
    "        output = torch.zeros(num_batch, num_classes, self.top_k, 5)\n",
    "\n",
    "        # change order of 'cof_data'\n",
    "        #   from [batch_num,8732,num_classes] to [batch_num, num_classes,8732]\n",
    "        conf_preds = conf_data.transpose(2, 1)\n",
    "\n",
    "        # mini-batch loop\n",
    "        for i in range(num_batch):\n",
    "\n",
    "            # 1. calculate BBox [xmin, ymin, xmax, ymax]  from 'loc' and DBox\n",
    "            decoded_boxes = decode(loc_data[i], dbox_list)\n",
    "\n",
    "            # copy 'conf'\n",
    "            conf_scores = conf_preds[i].clone()\n",
    "\n",
    "            # loop for object class (exclude background class=0, start from 1)\n",
    "            for cl in range(1, num_classes):\n",
    "\n",
    "                # 2.detect BBOx with larger 'conf' \n",
    "                #   get the index of conf over the threshold as 'c_mask'\n",
    "                c_mask = conf_scores[cl].gt(self.conf_thresh)\n",
    "                # gt:greater than\n",
    "                # c_mask =1 if conf_score > conf_thresh, otherwise 0\n",
    "                # conf_scores:torch.Size([21, 8732])\n",
    "                # c_mask:torch.Size([8732])\n",
    "\n",
    "                # scores: torch.Size([num of BBox exceeds threshold])\n",
    "                scores = conf_scores[cl][c_mask]\n",
    "\n",
    "                # if no BBox exceed threshold (i.e scores=[]), do nothing\n",
    "                if scores.nelement() == 0:  # nelement: find the total number of elements\n",
    "                    continue\n",
    "\n",
    "                # Resize 'c_mask' so that it can be applied to decoded_boxes\n",
    "                l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
    "                # l_mask:torch.Size([8732, 4])\n",
    "\n",
    "                # apply 'l_mask' to decoded_boxes (BBox)\n",
    "                boxes = decoded_boxes[l_mask].view(-1, 4)\n",
    "                # Because decoded_boxes[l_mask] is 1dim array,\n",
    "                #   reshape this to (num of BBox exceeds threshold, 4) with 'view'\n",
    "\n",
    "                # 3. remove highly overlapped BBOx with Non-Maximum Suppression (NMS)\n",
    "                ids, count = nm_suppression(\n",
    "                    boxes, scores, self.nms_thresh, self.top_k)\n",
    "                # ids：indexes that pass the NMS in descending order by 'conf'\n",
    "                # count：number of BBox passed NMS\n",
    "\n",
    "                # store results of the NMS in 'output'\n",
    "                output[i, cl, :count] = torch.cat((scores[ids[:count]].unsqueeze(1),\n",
    "                                                   boxes[ids[:count]]), 1)\n",
    "\n",
    "        return output  # torch.Size([1, 21, 200, 5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement of SSD class (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55Sgd5HBGw9b"
   },
   "outputs": [],
   "source": [
    "# definition of SSD class\n",
    "\n",
    "\n",
    "class SSD(nn.Module):\n",
    "\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "\n",
    "        self.phase = phase  # select train or inference\n",
    "        self.num_classes = cfg[\"num_classes\"]  # num_class=21\n",
    "\n",
    "        # create SSD network\n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(\n",
    "            cfg[\"num_classes\"], cfg[\"bbox_aspect_num\"])\n",
    "\n",
    "        # create DBox\n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "        # in inference phase, \"Detect\" class is used.\n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect()\n",
    "\n",
    "    def forward(self, x):\n",
    "        sources = list()  # to store source1-source6: input to 'loc' and 'conf'\n",
    "        loc = list()   # to store 'loc' output\n",
    "        conf = list()  # to store 'conf' output \n",
    "\n",
    "        # calc conv4_3 in VGG (until 22 layer)\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "\n",
    "        # source 1: conv4_3 -> L2Norm, add sources\n",
    "        source1 = self.L2Norm(x)\n",
    "        sources.append(source1)\n",
    "\n",
    "        # source 2: calc until the last of VGG (conv6_2), add sources\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "\n",
    "        sources.append(x)\n",
    "\n",
    "        # calculation of (source3- source6) in 'extras' \n",
    "        #   and add them to 'sources'.\n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace=True) # v(x) is conv \n",
    "            if k % 2 == 1:  # append 'sources' after each conv→ReLU→conv→ReLU processes\n",
    "                sources.append(x)\n",
    "\n",
    "        # perform one 3x3 conv process for each source1 - source6\n",
    "        # Get multiple list elements of the for loop with\n",
    "        #        (i.e 6 loops : (source1 to source6)\n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            # reorders the elements (and reposition of elements in the memory)\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "            # perform convolution for source x -> loc l(x) and conf c(x)\n",
    "            # size of l(x) and c(x) is \n",
    "            #     [batch_num, 4*num the type of aspect ratio, height of map, width of map]\n",
    "            # Since the number of aspect ratios of DBOX varies from source to source (4 or 6), \n",
    "            #        for the sake of convenience, this dimension is replaced to the end.\n",
    "            #     [batch_num, height of map, width of map, 4*num the type of aspect ratio]\n",
    "            #\n",
    "            # （Note）\n",
    "            # torch.continuous() is an instruction to reposition elements sequentially in memory.\n",
    "            # In order to use [view] comamands used in laterto work, \n",
    "            #        the target variable must be contiguous in memory.\n",
    "\n",
    "        # reshape (flatten) 'loc' and 'conf' into one-dim/image\n",
    "        # loc:  torch.Size([batch_num, 34928])\n",
    "        # conf: torch.Size([batch_num, 183372])\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "\n",
    "        # further reshape them \n",
    "        # loc:  torch.Size([batch_num, 8732, 4])\n",
    "        # conf: torch.Size([batch_num, 8732, 21])\n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        conf = conf.view(conf.size(0), -1, self.num_classes)\n",
    "\n",
    "        # summarize them as 'output'\n",
    "        output = (loc, conf, self.dbox_list)\n",
    "\n",
    "        if self.phase == \"inference\":  # at the inference\n",
    "            # execute [forward] in Detect class\n",
    "            # return size: torch.Size([batch_num, 21, 200, 5])\n",
    "            return self.detect(output[0], output[1], output[2])\n",
    "\n",
    "        else:  # at the training \n",
    "            return output\n",
    "            # return size: (loc, conf, dbox_list)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2-4-5_SSD_model_forward.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
